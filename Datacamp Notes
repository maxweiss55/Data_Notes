__________________________________________________________________________
__________________________________________________________________________
*****INTRO TO TIDYVERSE*****
__________________________________________________________________________
__________________________________________________________________________

##DOWNLOAD PACKAGES##

>>library(package/dataset)

library(dplyr)
library(tidyverse)
library(ggplot2)

__________________________________________________________________________

##FILTER##

>>filter(df, condition)

filter(gapminder, year == 2007, country == “United States”)

gapminder %>%
  filter(lifeExp > 75)

__________________________________________________________________________

##ARRANGE##

>>arrange(df, variable)

arrange(gapminder, gdp)

gapminder %>%
  arrange(desc(lifeExp))
  
__________________________________________________________________________

##MUTATE##
#Add variable to dataframe

>>mutate(df, variable = operation)

mutate(gapminder, lifeExpMonths = lifeExp*12)

gapminder %>%
  mutate(lifeExpMonths = lifeExp*12)
  
__________________________________________________________________________

##SUMMARIZE##

>>summarize(df, variable = function(var1)

summarize(gapminder, medianLifeExp = mean(lifeExp))

gapminder %>%
  summarize(medianLifeExp = median(lifeExp))
  
__________________________________________________________________________

##GROUP BY##

>>group_by(df, var1)

group_by(gapminder, year)

gapminder %>%
  group_by(year) %>%
  summarize(medianLifeExp = median(lifeExp), 
  maxGdpPercap = max(gdpPercap))
  
__________________________________________________________________________

##GGPLOT##
library(ggplot2)

>>ggplot(df, aes(x = var1, y = var2)) + #make ggplot
>>  geom_point() + #scatterplot


ggplot(gapminder_1952, aes(x = pop, y = lifeExp, color = continent, 
       size = gdpPercap)) +
  geom_point() +
  geom_line() +     #line plot
  geom_col() +      #bar plot
  geom_histogram(binwidth = 5) +      #histogram
  geom_boxplot() +      #boxplot
  scale_x_log10() +       #scale x by log10
  facet_wrap(~ continent) +       #FACET WRAP (different panels) # the ~ is "by"
  expand_limits(y=0) +      #expand y axis
  ggtitle("Comparing GDP per capita across continents")       #title


USING "<-" to plot certain things

by_year <- gapminder %>%
  group_by(year) %>%
  summarize(medianLifeExp = median(lifeExp),
            maxGdpPercap = max(gdpPercap))
            
ggplot(by_year, aes(x=year, y=medianLifeExp)) +
  geom_point()+
  expand_limits(y=0)
__________________________________________________________________________
__________________________________________________________________________
*****GGPLOT2 Data Visualization with ggplot2 (Part 1)*****
__________________________________________________________________________
__________________________________________________________________________

>>ggplot(df, aes(x = var1, y = var2)) + 
>>  something(anything)


ggplot(diamonds, aes(x = carat, y = price)) +
  geom_point() +
  geom_smooth() #Add a smooth line


Quick and Dirty Plot: plot(mtcars$wt, mtcars$mpg, col = mtcars$cyl)
#See this lesson for more on this


#TIDYING???

ggplot(iris.tidy, aes(x = Species, y = Value, col = Part)) +
  geom_jitter() ##Tidy mechanism

iris.wide <- iris %>%
  gather(key, value, -Species, -Flower) %>%
  separate(key, c("Part", "Measure"), "\\.") %>%
  spread(Measure, value)


#AESTHETICS#

ggplot(mtcars, aes(x = wt, y = mpg, fill = cyl, col = am)) +
  geom_point(shape = 21, size = 4, alpha = 0.6)
  
#Above is not where the col, shape, size, etc. go...
#...any of these could be in ggplot(aes()) or geom_point()...
#...but would need (i.e. shape = 21 vs shape = var1) and give different results

ggplot(mtcars, aes(x = wt, y = mpg, label = cyl)) +
  geom_text() #Use the text as points


#GEOMETRIES#

val = c("#E41A1C", "#377EB8")
lab = c("Manual", "Automatic")
ggplot(mtcars,  aes(x = wt, y = mpg))+
  geom_bar(position = "dodge") +
  scale_x_discrete("Cylinders") + 
  scale_y_continuous("Number") +
  scale_fill_manual("Transmission", 
                    values = c("#E41A1C", "#377EB8"),
                    labels = c("Manuall", "Automatic")) 

ggplot(mtcars, aes(x = mpg, y = 0)) +
  geom_jitter(shape = 1) + #jitter things up
  scale_y_continuous(limits=c(-2,2))

# Draw a bar plot of cyl, filled according to am
ggplot(mtcars, aes(x = cyl, fill = am)) +
  geom_bar()
# Change the position argument to stack
ggplot(mtcars, aes(x = cyl, fill = am)) +
  geom_bar(position = "stack")
# Change the position argument to fill
ggplot(mtcars, aes(x = cyl, fill = am)) +
  geom_bar(position = "fill")
# Change the position argument to dodge
ggplot(mtcars, aes(x = cyl, fill = am)) +
  geom_bar(position = "dodge")
# Change geom to freqpoly (position is identity by default)
ggplot(mtcars, aes(mpg, color=cyl)) +
  geom_freqpoly(binwidth = 1, position="identity")
# Example of how to use a brewed color palette
ggplot(mtcars, aes(x = cyl, fill = am)) +
  geom_bar() +
  scale_fill_brewer(palette = "Set1")
# Expand the following command with geom_rect() to draw the recess periods
ggplot(economics, aes(x = date, y = unemploy/pop)) +
  geom_rect(data = recess,
         aes(xmin = begin, xmax = end, ymin = -Inf, ymax = +Inf),
         inherit.aes = FALSE, fill = "red", alpha = 0.2) +
  geom_line()

__________________________________________________________________________
__________________________________________________________________________
*****WORKING WITH RSTUDIO IDE*****
__________________________________________________________________________
__________________________________________________________________________

#Clear Console#
Control + L

#Read in CSV#
read.csv()

#RUN CODE#
Command + Enter     #Run selected code
Command + Shift + S     #Source code, run code no output
Command + Shift + Enter       #Run everything

#View#
view(df)


#Panes Exist#


#Key board Shortcuts#

Command + Shift + M     #Pipe Operator %>%
Option + -      #Assignment arrow <-
Control + Shift + C       #Comment Out Something "#"
Option + Shift + K      #All Keyboard Shortcuts!
Command + Shift + Option + G      #Go to line number
Command + F      #Find or Find and Replace
Command + Option + o      #Close folds
Command + Option + Shift + o  #Open Folds
Control + P       #Navigate to paired symbol

#Packrat#

__________________________________________________________________________
__________________________________________________________________________
*****DPLYR: DATA MANIPULATION IN R WITH DPLYR*****
__________________________________________________________________________
__________________________________________________________________________

head(df)
summary(df)

#tbl#

dataframename_tbl <- tbl_df(dataframename)

two <- c("AA", "AS")
lut <- c("AA" = "American", 
         "AS" = "Alaska", 
         "B6" = "JetBlue")
two <- lut[two]
two

__________________________________________________________________________

##SELECT##
#Print only these columns

>>select(df, var1, var2)

select(hflights,ArrDelay,DepDelay)
select(hflights, UniqueCarrier, FlightNum, TailNum, contains("Cancel"))

starts_with("X"); ends_with("X"); contains("X"); matches("X"); 
num_range("x", 1:5): the variables named x01, x02, x03, x04 and x05,;
one_of(x): every name that appears in x, which should be a character vector.
  
__________________________________________________________________________

##SELECT##
#Print only these columns

>>select(df, var1, var2)

select(hflights,ArrDelay,DepDelay)
select(hflights, UniqueCarrier, FlightNum, TailNum, contains("Cancel"))

starts_with("X"); ends_with("X"); contains("X"); matches("X"); 
num_range("x", 1:5): the variables named x01, x02, x03, x04 and x05,;
one_of(x): every name that appears in x, which should be a character vector.
  
__________________________________________________________________________

##MUTATE##
#Add a column

mutate(df, z = x + y)

g2 <- mutate(g1, GroundTime = TaxiIn + TaxiOut)

__________________________________________________________________________

##FILTER##
#Extract all rows where this is true

mutate(df, z = x + y)

g2 <- mutate(g1, GroundTime = TaxiIn + TaxiOut)

# All flights flown by one of JetBlue, Southwest, or Delta
filter(hflights, UniqueCarrier %in% c("JetBlue", "Southwest", "Delta"))

__________________________________________________________________________

##ARRANGE##
#Arrange

mutate(df,var)

# Arrange dtc according to carrier and departure delays
arrange(dtc, UniqueCarrier, DepDelay)

__________________________________________________________________________

##SUMMARISE##
#Summarise

summarise(df, name = agg_funct())

Aggregate Functions:
first(x) - The first element of vector x.
last(x) - The last element of vector x.
nth(x, n) - The nth element of vector x.
n() - The number of rows in the data.frame or group of observations that summarise() describes.
n_distinct(x) - The number of unique values in vector x.

summarise(hflights, 
          n_obs = n(), 
          n_carrier = n_distinct(UniqueCarrier), 
          n_dest = n_distinct(Dest))

__________________________________________________________________________

##PIPE##
#Pipe

%>%

hflights
hflights %>%
  mutate(RealTime = ActualElapsedTime + 100) %>%
  mutate(mph = Distance / RealTime * 60) %>%
  filter(!is.na(mph)) %>%
  filter(mph < 70) %>%
  summarize(
            n_less=n(),
            n_dest=n_distinct(Dest),
            min_dist=min(Distance),
            max_dist=max(Distance)
            )
__________________________________________________________________________

##GROUP_BY##
#Group

group_by(df, var)

hflights %>%
  filter(!is.na(ArrDelay)) %>%
  filter(ArrDelay > 0 ) %>%
  group_by(UniqueCarrier) %>%
  summarise(avg = mean(ArrDelay)) %>%
  mutate(rank = rank(avg)) %>%
  arrange(rank)

__________________________________________________________________________
__________________________________________________________________________
*****REPORTING WITH R MARKDOWN*****
__________________________________________________________________________
__________________________________________________________________________

##Styling narrative sections##

You can use Markdown to embed formatting instructions into your text. For example, you can make a word italicized by surrounding it in asterisks, bold by surrounding it in two asterisks, and monospaced (like code) by surrounding it in backticks:

*italics*
**bold**
`code`

You can turn a word into a link by surrounding it in hard brackets and then placing the link behind it in parentheses, like this:

[RStudio](www.rstudio.com)

To create titles and headers, use leading hastags. The number of hashtags determines the header's level:

# First level header
## Second level header
### Third level header

To make a bulleted list in Markdown, place each item on a new line after an asterisk and a space, like this:

* item 1
* item 2
* item 3

You can make an ordered list by placing each item on a new line after a number followed by a period followed by a space, like this

1. item 1
2. item 2
3. item 3

To embed an equation in its own centered equation block, surround the equation with two pairs of dollar signs like this,

$$1 + 1 = 2$$
To embed an equation inline, surround it with a single pair of dollar signs, like this: $1 + 1 = 2$

__________________________________________________________________________

Knitr

```{r}
# some code
```

```{r warning = FALSE, error = FALSE}
"four" + "five"
```

If echo = FALSE, R Markdown will not display the code in the final document 
(but it will still run the code and display its results unless told otherwise).

If eval = FALSE, R Markdown will not run the code or include its results, 
(but it will still display the code unless told otherwise).

If results = 'hide', R Markdown will not display the results of the code 
(but it will still run the code and display the code itself unless told otherwise).


The factorial of four is `r factorial(4)`.

```{r ref.label='simple_sum', echo = FALSE}
```

changing the output field to:

---
output: beamer_presentation
---
which creates a beamer pdf slideshow,

---
output: ioslides_presentation
---
which creates an ioslides HTML slideshow or

---
output: slidy_presentation
---
which creates a slidy HTML slideshow.

R Markdown will start a new slide at each first or second level header in your document. You can insert additional slide breaks with Markdown's horizontal rule syntax:

***

Everywhere you add these three asterisks in your text, pandoc will create a new slide.

pdf_document template to create a document that uses the zenburn style:

    ---
    title: "Demo"
    output:
      pdf_document:
        highlight: zenburn
    ---
__________________________________________________________________________

SHINY????

__________________________________________________________________________
__________________________________________________________________________
*****THE SHELL: Intro to Shell for Datascience*****
__________________________________________________________________________
__________________________________________________________________________

pwd #Where am I? Print working directory.

ls      #listing what is in current directory
ls /argument      #listing what is in this directory
ls /home/repl/seasonal

"/" slash at front means absolute path; without is relative (shortened) path

cd      #switch to new directory
cd directory      #switch to indicated directoryls

..      #means parent directory/directory above
.       #means current directory
~       #Your home directory

cp filedirectry newfiledirectory      #copy filedirectory to new filedirectory

mv filedirectry newfiledirectory      #move filedirectory to new file

mv course.txt old-course.txt      #rename file

rm filename      #remove file

rmdir       #directory

mkdir directory_name      #make new directory

/tmp      #make new temporary directory

cat file      #show contents of file

You can use cat to print large files and then scroll through the output, 
but it is usually more convenient to page the output. 
The original command for doing this was called more, 
but it has been superseded by a more powerful command called less. 
When you less a file, one page is displayed at a time; 
you can press spacebar to page down or type q to quit.

If you give less the names of several files, 
you can type :n (colon and a lower-case 'n') to move to the next file, 
:p to go back to the previous one, or :q to quit.

head file       #see start of file
head -n 3 seasonal/summer.csv

ls -R -F      #Show every file in current directory and subdirectory

cut -f 2-5,8 -d , values.csv      #select certain rows from a file

grep can search for patterns as well; we will explore those in the next course. What's more important right now is some of grep's more common flags:

-c: print a count of matching lines rather than the lines themselves
-h: do not print the names of files when searching multiple files
-i: ignore case (e.g., treat "Regression" and "regression" as matches)
-l: print the names of files that contain matches, not the matches
-n: print line numbers for matching lines
-v: invert the match, i.e., only show lines that don't match

As its name suggests, sort puts data in order.

Another command that is often used with sort is uniq, whose job is to remove duplicated lines. 

"|" is the pipe operator

Variable	Purpose	Value
HOME	User's home directory	/home/repl
PWD	Present working directory	Same as pwd command
SHELL	Which shell program is being used	/bin/bash
USER	User's ID	repl

echo      #will print out what follows
Varname = something      #set variable
$varname      #print what the variable is saved as

for filename in seasonal/*.csv; do echo $filename; done

nano filename     #text editor

__________________________________________________________________________
__________________________________________________________________________
*****DATA IN TIDYVERSE*****
__________________________________________________________________________
__________________________________________________________________________

library(readr)

read_csv("Path")      #read in a csv
name <- read_csv("Path")

read_csv("Path", skip = 1)      #Skip the first row (regarding heading esp.)

is.na() 1     #Identify rows with missing data

bakeoff %>%
  filter(!is.na(us_season))     #Filter to only the rows where us_season is NOT (!) MISSING

glimpse(datatablename)      #glimpse the whole table

library(skimr)
skim(datatablename)       #Do some quick skimming of each column

distinct(variable)    #Show the distinct values for given variable

count(variable)     #Count the number of each distinct value for given variable

Can also do logical condition... count(variable == "Value")

Cast Column Types / Parsing:
parse_number("36 years")      #Will return 36 (Look up how to do date stuff)

desserts <- read_csv("desserts.csv",
                      col_types = cols(technical = col_number()),       #Cast Column type (number)
                      na = c("", "NA", "N/A"))        #This defines what empty cells are defined as.First two = default

desserts <- desserts %>% 
  mutate(tech_win = recode(technical, `1` = 1, .default = 0))
  
ratings %>% 
  select(channel, everything())       #keep everything but move channel column to the front

library(tidyr)


GATHER

Untidy_data %>%
  gather(key = "keycolumnname", value = "valuecolumnname", column_1:column_7)

tidy_ratings <- ratings %>%
    gather(key = "episode", value = "viewers_7day", -series, 
           factor_key = TRUE, na.rm = TRUE) %>% 
    arrange(series, episode) %>% 
    mutate(episode_count = row_number()) 
    
SEPARATE

juniors_untidy %>%
  separate(col = spice, into = c('spice', 'order'), convert = TRUE)
            #column you have      #columns you want

UNITE
  unite()     #opposite of spread
  
SPREAD

juniors_jumbled %>%
  spread(key = key, value = value, convert = TRUE)

tidy_ratings_all <- ratings2 %>%
    gather(episode, viewers, ends_with("day"), na.rm = TRUE) %>% 
    separate(episode, into = c("episode", "days")) %>%  
    mutate(episode = parse_number(episode),
           days = parse_number(days))

juniors_multi %>% 
  gather(key = "key", value = "value", score_1:guess_3) %>% 
  separate(key, into = c("var", "order"), convert = TRUE) %>% 
  spread(var, value)

__________________________________________________________________________
__________________________________________________________________________
*****MODELLING TIDYVERSE*****
__________________________________________________________________________
__________________________________________________________________________

# Code to create scatterplot
ggplot(evals, aes(x = age, y = score)) +
  geom_point() + 
  labs(x = "age", y = "score", title = "Teaching score over age")
# Add a "best-fitting" line
ggplot(evals, aes(x = age, y = score)) +
  geom_point() + 
  labs(x = "age", y = "score", title = "Teaching score over age") +
  geom_smooth(method = "lm", se = FALSE)
  
  
# Fit regression model using formula of form: y ~ x
model_score_1 <- lm(score ~ age, data = evals)
# Output contents
model_score_1
Call:
lm(formula = score ~ age, data = evals)

   
# Fit regression model using formula of form: y ~ x
model_score_1 <- lm(score ~ age, data = evals)

# Output regression table using wrapper function:
get_regression_table(model_score_1)

# Fit regression model using formula of form: y ~ x
model_score_1 <- lm(score ~ age, data = evals)
# Get information on each point
get_regression_points(model_score_1)

# Fit regression model
model_score_3 <- lm(score ~ gender, data = evals)

# Get regression points
model_score_3_points <- get_regression_points(model_score_3)
model_score_3_points
# Plot residuals
ggplot(model_score_3_points, aes(x = residual)) +
  geom_histogram() +
  labs(x = "residuals", title = "Residuals from score ~ gender model")

# Fit regression model using formula of form: y ~ x1 + x2
model_price_1 <- lm(log10_price ~ log10_size + yr_built, 
                    data = house_prices)
# Output regression table
get_regression_table(model_price_1)

# Create data frame of "new" houses
new_houses <- data_frame(
  log10_size = c(2.9, 3.6),
  condition = factor(c(3, 4))
)
new_houses

get_regression_points(model_price_3, newdata = new_houses)

model_price_3 <- lm(log10_price ~ log10_size + condition, 
                    data = house_prices)
get_regression_points(model_price_3) %>%
  mutate(sq_residuals = residual^2) %>%
  summarize(sum_sq_residuals = sum(sq_residuals))
  
summarize(r_squared = 1 - var(residual) / var(log10_price))

get_regression_points(model_price_1) %>%
  mutate(sq_residuals = residual^2) %>%
  summarize(sum_sq_residuals = sum(sq_residuals))
  
# Mean squared error: use mean() instead of sum():
get_regression_points(model_price_1) %>%
  mutate(sq_residuals = residual^2) %>%
  summarize(mse = mean(sq_residuals))%>%
  mutate(rmse = sqrt(mse))
 
# Recreate data frame of "new" houses
new_houses <- data_frame(
  log10_size = c(2.9, 3.6),
  condition = factor(c(3, 4))
)

get_regression_points(model_price_3, newdata = new_houses)
 
# Randomly shuffle order of rows:
house_prices_shuffled <- house_prices %>% 
  sample_frac(size = 1, replace = FALSE)
# Split into train and test:
train <- house_prices_shuffled %>%
  slice(1:10000)
test <- house_prices_shuffled %>%
  slice(10001:21613)
  
# Train model on train:
train_model_price_1 <- lm(log10_price ~ log10_size + yr_built,
                          data = train)

# Get predictions on test:
get_regression_points(train_model_price_1, newdata = test)

# Train model:
train_model_price_3 <- lm(log10_price ~ log10_size + condition,
                          data = train)

# Get predictions and compute RMSE:
get_regression_points(train_model_price_3, newdata = test) %>%
  mutate(sq_residuals = residual^2) %>%
  summarize(rmse = sqrt(mean(sq_residuals)))

__________________________________________________________________________
__________________________________________________________________________
*****WORKING WITH WEB DATA*****
__________________________________________________________________________
__________________________________________________________________________

read.csv("http://website.url/remote-file.csv")

download.file(
    url = "http://website.url/remote-file.csv", 
    destfile = "local-file.csv"
)

# Add a new column: square_weight
csv_data$square_weight <- (csv_data$weight)^2

# Save it to disk with saveRDS()
saveRDS(object = csv_data, file = "modified_feed_data.RDS")

# Read it back in with readRDS()
modified_feed_data <- readRDS(file ="modified_feed_data.RDS")

# Examine modified_feed_data
str(modified_feed_data)

library(pageviews)
article_pageviews(article = "R_(programming_language)")

response <- GET(url = "https://httpbin.org/get")
content(response)
post_result <- POST(url = "http://httpbin.org/post", body = "this is a test")

# Construct a directory-based API URL to `http://swapi.co/api`,
# looking for person `1` in `people`
directory_url <- paste("http://swapi.co/api", "people", 1, sep = "/")

# Make a GET call with it
result <- GET(url = directory_url)

library(httr)
url <- "http://httpbin.org/get"
r <- GET(url)
http_type(r)

writeLines(content(r, as = "text"))

XPATH	Meaning
/node	Elements with tag node at this level
//node	Elements with tag node anywhere at or below this level
@attr	Attribute with name attr
 

Get nodes with xml_find_all()
Extract contents with xml_double(), xml_integer() or as_list()

fromJSON(movies_json, simplifyVector = FALSE)

read_html(url = ___)

html_node()

html_text(x = ___) - get text contents
html_attr(x = ___, name = ___) - get specific attribute
html_name(x = ___) - get tag name


__________________________________________________________________________
__________________________________________________________________________
*****CORRELATION AND REGRESSION*****
__________________________________________________________________________
__________________________________________________________________________

If it is helpful, you can think of boxplots as scatterplots for 
which the variable on the x-axis has been discretized.

The cut() function takes two arguments: the continuous variable you want to 
<<DISCRETIZE>> and the number of breaks that you want to make in that continuous 
variable in order to discretize it.

ggplot(data = ncbirths, 
       aes(x = cut(weeks, breaks = 5), y = weight)) + 
  geom_boxplot()
  
CORRELATION

# Compute correlation
ncbirths %>%
  summarize(N = n(), r = cor(weight, mage))

# Compute correlation for all non-missing pairs
ncbirths %>%
  summarize(N = n(), r = cor(weight, weeks, use = "pairwise.complete.obs"))

ggplot(data = bdims, aes(x = hgt, y = wgt)) + 
  geom_point() + 
  geom_smooth(method = "lm", se = FALSE)

LINEAR MODEL

mod <- lm(wgt ~ hgt, data = bdims)

# Show the coefficients
coef(mod)

# Show the full output
summary(mod)

fitted.values(mod)

residuals(mod)

# Load broom
library(broom)

# Create bdims_tidy
bdims_tidy = augment(mod)

# Glimpse the resulting data frame
glimpse(bdims_tidy)

predict(mod, newdataframe)

# Compute RMSE
sqrt(sum(residuals(mod)^2) / df.residual(mod))

# View model summary
summary(mod)

# Compute R-squared
bdims_tidy %>%
  summarize(var_y = var(wgt), var_e = var(residuals(mod))) %>%
  mutate(R_squared = 1 - var_e / var_y)
  
# Rank points of high leverage
mod %>%
  augment() %>%
  arrange(desc(.hat)) %>%
  head()

#Rank influential points
mod %>%
  augment() %>%
  arrange(desc(.cooksd)) %>%
  head()

__________________________________________________________________________
__________________________________________________________________________
*****SHINY*****
__________________________________________________________________________
__________________________________________________________________________

library(shiny)
library(ggplot2)
load(url("http://s3.amazonaws.com/assets.datacamp.com/production/course_4850/datasets/movies.Rdata"))

# Define UI for application that plots features of movies 
ui <- fluidPage(
  
  # Sidebar layout with a input and output definitions 
  sidebarLayout(
    
    # Inputs
    sidebarPanel(
      
      # Select variable for y-axis
      selectInput(inputId = "y", 
                  label = "Y-axis:",
                  choices = c("imdb_rating", "imdb_num_votes", "critics_score", "audience_score", "runtime"), 
                  selected = "audience_score"),
      # Select variable for x-axis
      selectInput(inputId = "x", 
                  label = "X-axis:",
                  choices = c("imdb_rating", "imdb_num_votes", "critics_score", "audience_score", "runtime"), 
                  selected = "critics_score")
    ),
    
    # Outputs
    mainPanel(
      plotOutput(outputId = "scatterplot")
    )
  )
)

# Define server function required to create the scatterplot
server <- function(input, output) {

  # Create scatterplot object the plotOutput function is expecting
  output$scatterplot <- renderPlot({
    ggplot(data = movies, aes_string(x = input$x, y = input$y)) +
      geom_point()
  })
}

# Create a Shiny app object
shinyApp(ui = ui, server = server)


_______________________________________________________

library(shiny)
library(ggplot2)
load(url("http://s3.amazonaws.com/assets.datacamp.com/production/course_4850/datasets/movies.Rdata"))

# Define UI for application that plots features of movies
ui <- fluidPage(
  
  # Sidebar layout with a input and output definitions
  sidebarLayout(
    
    # Inputs
    sidebarPanel(
      
      # Select variable for y-axis
      selectInput(inputId = "y", 
                  label = "Y-axis:",
                  choices = c("imdb_rating", "imdb_num_votes", "critics_score", "audience_score", "runtime"), 
                  selected = "audience_score"),
      
      # Select variable for x-axis
      selectInput(inputId = "x", 
                  label = "X-axis:",
                  choices = c("imdb_rating", "imdb_num_votes", "critics_score", "audience_score", "runtime"), 
                  selected = "critics_score"),
      
      # Select variable for color
      selectInput(inputId = "z", 
                  label = "Color by:",
                  choices = c("title_type", "genre", "mpaa_rating", "critics_rating", "audience_rating"),
                  selected = "mpaa_rating")
    ),
    
    # Outputs
    mainPanel(
      plotOutput(outputId = "scatterplot")
    )
  )
)

# Define server function required to create the scatterplot
server <- function(input, output) {
  
  # Create the scatterplot object the plotOutput function is expecting
  output$scatterplot <- renderPlot({
    ggplot(data = movies, aes_string(x = input$x, y = input$y,
                                     color = input$z)) +
      geom_point()
  })
}

# Create a Shiny app object
shinyApp(ui = ui, server = server)

__________________________________________________________________________
__________________________________________________________________________
*****DATA CLEANING*****
__________________________________________________________________________
__________________________________________________________________________

gather(widedf, my_key, my_value, columnstogatherornottogather)

spread(longdf, my_key, my_value)



bmi_cc_clean <- separate(bmi_cc, col = Country_ISO, into = c("Country", "ISO"), sep = "/")

bmi_cc <- unite(bmi_cc_clean, Country_ISO, Country, ISO, sep = "-")



TYPES

as.character(2016)
>"2016"

as.numeric(TRUE)
>1

as.integer(99)
>99

as.factor("something")
>something
Levels: something

as.logical(0)
>FALSE

students$Grades <- as.character(students$Grades)
students$Fedu <- as.factor(students$Fedu)


LUBRDIDATE 

# Load the lubridate package
library(lubridate)
ymd_hms("2016, August 5, 12:59:02")

# Parse as date
dmy("17 Sep 2015")

# Parse as date and time (with no seconds!)
mdy_hm("July 15, 2012 12:56")


STRINGR

library(stringr

# Load the stringr package
library(stringr)

# Trim all leading and trailing whitespace
str_trim(c("   Filip ", "Nick  ", " Jonathan"))

# Pad these strings with leading zeros
str_pad(c("23485W", "8823453Q", "994Z"), width = 9, side = "left", pad = "0")

# Print state abbreviations
print(states)

# Make states all uppercase and save result to states_upper
states_upper <- toupper(states)

# Make states_upper all lowercase again
tolower(states_upper)


MISSING VALUES

# Call is.na() on the full social_df to spot all NAs
is.na(social_df)

# Use the any() function to ask whether there are any NAs in the data
any(is.na(social_df))

# View a summary() of the dataset
summary(social_df)

# Call table() on the status column
table(social_df$status)

## The stringr package is preloaded

# Replace all empty strings in status with NA
social_df$status[social_df$status == ""] <- NA

# Print social_df to the console
print(social_df)

# Use complete.cases() to see which rows have no missing values
complete.cases(social_df)

# Use na.omit() to remove all rows with any missing values
na.omit(social_df)

# Count missing values
sum(is.na(weather6))

# Find missing values
summary(weather6)

# Find indices of NAs in Max.Gust.SpeedMPH
ind <- which(is.na(weather6$Max.Gust.SpeedMPH))

# Look at the full rows for records missing Max.Gust.SpeedMPH
weather6[ind, ]

# Review distributions for all variables
summary(weather6)

# Find row with Max.Humidity of 1000
ind <- which(weather6$Max.Humidity == 1000)

# Look at the data for that day
weather6[ind, ]

# Change 1000 to 100
weather6$Max.Humidity[ind] <- 100

# Look at summary of Mean.VisibilityMiles
summary(weather6$Mean.VisibilityMiles)

# Get index of row with -1 value
ind <- which(weather6$Mean.VisibilityMiles == -1)

# Look at full row
weather6[ind, ]

# Set Mean.VisibilityMiles to the appropriate value
weather6$Mean.VisibilityMiles[ind] <- 10

# Clean up column names
names(weather6) <- new_colnames

# Replace empty cells in events column
weather6$events[weather6$events == ""] <- "None"
    
# Print the first 6 rows of weather6
head(weather6, 6)

__________________________________________________________________________
__________________________________________________________________________
*****DATA JOINING*****
__________________________________________________________________________
__________________________________________________________________________

# Finish the code below to recreate bands3 with a right join
bands2 <- left_join(bands, artists, by = c("first", "last"))
bands3 <- right_join(artists, bands, by = c("first", "last"))

# Join albums to songs using inner_join()
inner_join(songs, albums, by = "album")

# Join bands to artists using full_join()
full_join(artists, bands, by = c("first", "last"))

# View the output of semi_join()
artists %>% 
  semi_join(songs, by = c("first", "last"))
  
# Return rows of artists that don't have bands info
artists %>% 
  anti_join(bands, by = c("first", "last"))


aerosmith %>% 
  # Create the new dataset using a set operation
  union(greatest_hits) %>% 
  # Count the total number of songs
  nrow()
  
# Create the new dataset using a set operation
aerosmith %>% 
  intersect(greatest_hits)
  
# Create the new dataset using a set operation
live_songs %>% 
  setdiff(greatest_songs)
  
# Check if same order: definitive and complete
identical(definitive, complete)

# Check if any order: definitive and complete
setequal(definitive, complete)

# Songs in definitive but not complete
setdiff(definitive, complete)

# Songs in complete but not definitive
setdiff(complete, definitive)

# Bind side_one and side_two into a single dataset
side_one %>% 
  bind_rows(side_two)


# Make combined data frame using data_frame()
data_frame(year = hank_year, song = hank_song, peak = hank_peak) %>% 
  # Extract songs where peak equals 1
  filter(peak == 1)

stage_songs %>% 
  # Add row names as a column named song
  rownames_to_column(var = "song") %>% 
  # Left join stage_writers to stage_songs
  left_join(stage_writers)
  
elvis_movies %>% 
  # Left join elvis_songs to elvis_movies by this column
  left_join(elvis_songs, by = c("name" = "movie"))%>% 
  # Rename columns
  rename(song = name.y, movie = name)
  
# Load the purrr library
library(purrr)

# Place supergroups, more_bands, and more_artists into a list
list(supergroups, more_bands, more_artists) %>% 
  # Use reduce to join together the contents of the list
  reduce(left_join, by = c("first", "last"))
  

__________________________________________________________________________
__________________________________________________________________________
*****Interactive Maps with leaflet in R *****
__________________________________________________________________________
__________________________________________________________________________

library(leaflet)

leaflet() %>% 
   addTiles()
   
 leaflet() %>% 
   addProviderTiles("CartoDB") %>% 
   addMarkers(lng = dc_hq$lon, 
              lat = dc_hq$lat,
              popup = dc_hq$hq)

names(providers)[1:5]

  [1] "OpenStreetMap"                      
  [2] "OpenStreetMap.Mapnik"               
  [3] "OpenStreetMap.BlackAndWhite"        
  [4] "OpenStreetMap.DE"                   
  [5] "OpenStreetMap.France"
  
names(providers)[str_detect(names(providers), "OpenStreetMap")]

[1] "OpenStreetMap"               "OpenStreetMap.Mapnik"       
[3] "OpenStreetMap.BlackAndWhite" "OpenStreetMap.DE"           
[5] "OpenStreetMap.France"        "OpenStreetMap.HOT"

leaflet() %>% 
     # addTiles() 
     addProviderTiles("OpenStreetMap.BlackAndWhite")
 
 leaflet() %>% 
    addProviderTiles("Esri")
    
    
 library(ggmap)

 geocode("350 5th Ave, New York, NY 10118") 
 
 geocode(location, 
            output = c("latlon", "latlona", "more", "all"),
            source = c("google", "dsk"))

geocode("Colby College", output = "more", source = "google")

leaflet() %>% 
 addTiles() %>% 
 setView(lng = -73.98575, 
         lat = 40.74856, 
         zoom = 13)

leaflet() %>% 
 addTiles() %>% 
 fitBounds(
  lng1 = -73.910, lat1 = 40.773, 
  lng2 = -74.060, lat2 = 40.723)

leaflet(options = 
            leafletOptions(dragging = FALSE,
                           minZoom = 14, 
                           maxZoom = 18))  %>% 
     addProviderTiles("CartoDB")  %>% 
     setView(lng = -73.98575, lat = 40.74856, zoom = 18)

leaflet()  %>% 
     addTiles()  %>% 
     setView(lng = -73.98575, lat = 40.74856, zoom = 18) %>% 
     setMaxBounds(lng1 = -73.98575, 
                  lat1 = 40.74856, 
                  lng2 = -73.98575, 
                  lat2 = 40.74856)
                  
# add marker layer to map
leaflet() %>% 
     addTiles() %>% 
     addMarkers(lng = -73.98575, 
                lat = 40.74856)
                
dc_hq <- 
     tibble(
         hq  = c("DataCamp - NYC", "DataCamp - Belgium"),
         lon = c(-73.98575, 4.717863),
         lat = c(40.74856, 50.881363))

leaflet() %>% 
     addTiles() %>% 
     addMarkers(lng = dc_hq$lon, lat = dc_hq$lat)

# When piping a data frame into the leaflet function
# R will search for columns named lat/latitude and lon/lng/long/longitude  

dc_hq  %>% 
     leaflet() %>% 
     addTiles() %>% 
     addMarkers() 

leaflet() %>% 
     addTiles() %>% 
     addMarkers(lng = dc_hq$lon, lat = dc_hq$lat, popup = dc_hq$hq)

leaflet() %>% 
     addTiles() %>% 
     addPopups(lng = dc_hq$lon, lat = dc_hq$lat, popup = dc_hq$hq

m <- 
     leaflet() %>%
     addTiles()  %>% 
     setView(lng = dc_hq$lon[1], 
             lat = dc_hq$lat[1], 
             zoom = 12)
             
 m  %>%
     clearBounds()%>% 
     clearMarkers()  
 
 maine_colleges_map <- 
   leaflet() %>% 
    addProviderTiles("CartoDB")%>% 
    addMarkers(data = maine)
    
maine_colleges_map %>%
    addCircleMarkers(data = maine)
    
maine_colleges_map %>% 
   clearMarkers() %>% 
   addCircleMarkers(data = maine, 
                    radius = 3)
 
ipeds %>% 
 leaflet() %>% 
 addProviderTiles("CartoDB") %>% 
 addCircleMarkers(
  lng = ~lng, lat = ~lat, 
  popup = ~name, color = "#FF0000"
  
# ipeds is specified 3 times
leaflet() %>% 
addProviderTiles("CartoDB") %>% 
addCircleMarkers(
 lng = ipeds$lng, lat = ipeds$lat, 
 popup = ipeds$name, color = "red")
 
addCircleMarkers(popup = ~name)
addCircleMarkers(popup = ~paste0(name, "-", sector_label)
addCircleMarkers(popup = ~paste0("<b>",name,"</b>","<br/>",sector_label))

ipeds %>% 
    leaflet()  %>% 
    addProviderTiles("CartoDB")  %>% 
    addCircleMarkers(label = ~name, radius = 2)

OR <- ipeds %>% 
        filter(state == "OR")
pal <- colorFactor(palette = c("red", "blue", "#9b4a11"), 
                   levels = c("Public", "Private", "For-Profit"))
 oregon_colleges <- 
    OR %>% 
      leaflet() %>% 
        addProviderTiles("CartoDB") %>% 
        addCircleMarkers(radius = 2,
                         color = ~pal(sector_label),
                         label = ~name)
 oregon_colleges %>% 
    addLegend(position = "bottomright",
              pal = pal, 
              values = c("Public", "Private", "For-Profit")) 
              
admit <- admit %>% 
            filter(!is.na(rate),
                   rate < 50, 
                   rate > 0)
 pal <- colorNumeric(palette = "Reds", domain = c(1:50), reverse = TRUE)
 admit_map <- 
    admit %>% 
      leaflet() %>% 
      addProviderTiles("CartoDB")  %>% 
      addCircleMarkers(radius = 4, color = ~pal(rate), label = ~name)  %>%
      addLegend(title = "Admit Rate", pal = pal, values = c(1:50), 
            position = "bottomright")

library(RColorBrewer)
display.brewer.all()

__________________________________________________________________________
__________________________________________________________________________
***** STRINGR *****
__________________________________________________________________________
__________________________________________________________________________

# Format c(1.0011, 2.011, 1) with digits = 1
format(c(1.0011, 2.011, 1), digits = 1)

writeLines(rows)

paste("$", pretty_income, sep = "")

str_c() same as paste basically but better

boy_first_letter <- str_sub(boy_names, 0, 1)

str_c()
str_length()
str_sub()
str_detect()
str_subset()
str_count()
str_split()
str_replace()







